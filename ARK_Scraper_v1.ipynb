{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Notebook for Python ARK scraper development\n",
    "\n",
    "Some Technical Issues"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'pandas._libs.tslibs.fields'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_23788/1013633647.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mpandas\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mIPython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minteractiveshell\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mInteractiveShell\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mInteractiveShell\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mast_node_interactivity\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"all\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\conda\\anaconda3\\lib\\site-packages\\pandas\\__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     20\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     21\u001b[0m \u001b[1;31m# numpy compat\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 22\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mpandas\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcompat\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mis_numpy_dev\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0m_is_numpy_dev\u001b[0m  \u001b[1;31m# pyright: ignore # noqa:F401\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     23\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     24\u001b[0m \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\conda\\anaconda3\\lib\\site-packages\\pandas\\compat\\__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     23\u001b[0m )\n\u001b[0;32m     24\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mpandas\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcompat\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcompressors\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 25\u001b[1;33m from pandas.compat.numpy import (\n\u001b[0m\u001b[0;32m     26\u001b[0m     \u001b[0mis_numpy_dev\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     27\u001b[0m     \u001b[0mnp_version_under1p21\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\conda\\anaconda3\\lib\\site-packages\\pandas\\compat\\numpy\\__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mpandas\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mutil\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mversion\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mVersion\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;31m# numpy versioning\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\conda\\anaconda3\\lib\\site-packages\\pandas\\util\\__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# pyright: reportUnusedImport = false\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m from pandas.util._decorators import (  # noqa:F401\n\u001b[0m\u001b[0;32m      3\u001b[0m     \u001b[0mAppender\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m     \u001b[0mSubstitution\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[0mcache_readonly\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\conda\\anaconda3\\lib\\site-packages\\pandas\\util\\_decorators.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mwarnings\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 14\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mpandas\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_libs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mproperties\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mcache_readonly\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     15\u001b[0m from pandas._typing import (\n\u001b[0;32m     16\u001b[0m     \u001b[0mF\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\conda\\anaconda3\\lib\\site-packages\\pandas\\_libs\\__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 13\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mpandas\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_libs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minterval\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mInterval\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     14\u001b[0m from pandas._libs.tslibs import (\n\u001b[0;32m     15\u001b[0m     \u001b[0mNaT\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\conda\\anaconda3\\lib\\site-packages\\pandas\\_libs\\interval.pyx\u001b[0m in \u001b[0;36minit pandas._libs.interval\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mc:\\conda\\anaconda3\\lib\\site-packages\\pandas\\_libs\\hashtable.pyx\u001b[0m in \u001b[0;36minit pandas._libs.hashtable\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mc:\\conda\\anaconda3\\lib\\site-packages\\pandas\\_libs\\missing.pyx\u001b[0m in \u001b[0;36minit pandas._libs.missing\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mc:\\conda\\anaconda3\\lib\\site-packages\\pandas\\_libs\\tslibs\\__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     37\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     38\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mpandas\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_libs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtslibs\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mdtypes\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 39\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mpandas\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_libs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtslibs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconversion\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mlocalize_pydatetime\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     40\u001b[0m from pandas._libs.tslibs.dtypes import (\n\u001b[0;32m     41\u001b[0m     \u001b[0mResolution\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\conda\\anaconda3\\lib\\site-packages\\pandas\\_libs\\tslibs\\conversion.pyx\u001b[0m in \u001b[0;36minit pandas._libs.tslibs.conversion\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mc:\\conda\\anaconda3\\lib\\site-packages\\pandas\\_libs\\tslibs\\offsets.pyx\u001b[0m in \u001b[0;36minit pandas._libs.tslibs.offsets\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mc:\\conda\\anaconda3\\lib\\site-packages\\pandas\\_libs\\tslibs\\timestamps.pyx\u001b[0m in \u001b[0;36minit pandas._libs.tslibs.timestamps\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mc:\\conda\\anaconda3\\lib\\site-packages\\pandas\\_libs\\tslibs\\timedeltas.pyx\u001b[0m in \u001b[0;36minit pandas._libs.tslibs.timedeltas\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'pandas._libs.tslibs.fields'"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_dir = r'C:\\investment_ds\\ark_innovation\\ARK_TRACKER_Py\\Input' # Save raw input here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'ARKK': 'https://ark-funds.com/wp-content/uploads/funds-etf-csv/ARK_INNOVATION_ETF_ARKK_HOLDINGS.csv', 'ARKW': 'https://ark-funds.com/wp-content/uploads/funds-etf-csv/ARK_NEXT_GENERATION_INTERNET_ETF_ARKW_HOLDINGS.csv', 'ARKG': 'https://ark-funds.com/wp-content/uploads/funds-etf-csv/ARK_GENOMIC_REVOLUTION_ETF_ARKG_HOLDINGS.csv', 'ARKQ': 'https://ark-funds.com/wp-content/uploads/funds-etf-csv/ARK_AUTONOMOUS_TECH._&_ROBOTICS_ETF_ARKQ_HOLDINGS.csv', 'ARKF': 'https://ark-funds.com/wp-content/uploads/funds-etf-csv/ARK_FINTECH_INNOVATION_ETF_ARKF_HOLDINGS.csv', 'ARKX': 'https://ark-funds.com/wp-content/uploads/funds-etf-csv/ARK_SPACE_EXPLORATION_&_INNOVATION_ETF_ARKX_HOLDINGS.csv', 'PRNT': 'https://ark-funds.com/wp-content/uploads/funds-etf-csv/THE_3D_PRINTING_ETF_PRNT_HOLDINGS.csv', 'IZRL': 'https://ark-funds.com/wp-content/uploads/funds-etf-csv/ARK_ISRAEL_INNOVATIVE_TECHNOLOGY_ETF_IZRL_HOLDINGS.csv'}\n"
     ]
    }
   ],
   "source": [
    "fund_name_tuple = ('ARKK', 'ARKW', 'ARKG', 'ARKQ', 'ARKF', 'ARKX','PRNT','IZRL')\n",
    "\n",
    "fund_data_source_tuple = ('https://ark-funds.com/wp-content/uploads/funds-etf-csv/ARK_INNOVATION_ETF_ARKK_HOLDINGS.csv',\n",
    "'https://ark-funds.com/wp-content/uploads/funds-etf-csv/ARK_NEXT_GENERATION_INTERNET_ETF_ARKW_HOLDINGS.csv',\n",
    "'https://ark-funds.com/wp-content/uploads/funds-etf-csv/ARK_GENOMIC_REVOLUTION_ETF_ARKG_HOLDINGS.csv',\n",
    "'https://ark-funds.com/wp-content/uploads/funds-etf-csv/ARK_AUTONOMOUS_TECH._&_ROBOTICS_ETF_ARKQ_HOLDINGS.csv',\n",
    "'https://ark-funds.com/wp-content/uploads/funds-etf-csv/ARK_FINTECH_INNOVATION_ETF_ARKF_HOLDINGS.csv',\n",
    "'https://ark-funds.com/wp-content/uploads/funds-etf-csv/ARK_SPACE_EXPLORATION_&_INNOVATION_ETF_ARKX_HOLDINGS.csv',\n",
    "'https://ark-funds.com/wp-content/uploads/funds-etf-csv/THE_3D_PRINTING_ETF_PRNT_HOLDINGS.csv',\n",
    "'https://ark-funds.com/wp-content/uploads/funds-etf-csv/ARK_ISRAEL_INNOVATIVE_TECHNOLOGY_ETF_IZRL_HOLDINGS.csv')\n",
    "\n",
    "input_dic = dict(zip(fund_name_tuple, fund_data_source_tuple))\n",
    "print(input_dic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ARKK data is loaded!\n",
      "ARKW data is loaded!\n",
      "ARKG data is loaded!\n",
      "ARKQ data is loaded!\n",
      "ARKF data is loaded!\n",
      "ARKX data is loaded!\n",
      "PRNT data is loaded!\n",
      "IZRL data is loaded!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "dict_keys(['ARKK', 'ARKW', 'ARKG', 'ARKQ', 'ARKF', 'ARKX', 'PRNT', 'IZRL'])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def read_web(select_fund, input_dict = input_dic, fund_name = fund_name_tuple):\n",
    "    if select_fund not in fund_name:\n",
    "        print(\"Please select fund from the tuple: {0:s}\".format(str(fund_name)))\n",
    "    else:\n",
    "        url = input_dict[select_fund]\n",
    "        storage_options = {'User-Agent': 'Chrome/108.0.5359.125'} # Need to specifify this line to read web file\n",
    "        fund_raw_ds = pd.read_csv(url, storage_options=storage_options) \n",
    "\n",
    "        print('{0} data is loaded!'.format(select_fund))\n",
    "\n",
    "        return fund_raw_ds\n",
    "\n",
    "fund_raw_dic = dict(zip(fund_name_tuple, (read_web(i) for i in fund_name_tuple)))\n",
    "\n",
    "fund_raw_dic.keys()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_validation_wrapper(input_dic, fund_name):\n",
    "    \n",
    "    input_ds = input_dic[fund_name]\n",
    "\n",
    "    def data_validation(input = input_ds):\n",
    "    # validate if col is modified\n",
    "    # input - the raw data frame\n",
    "        col_20230110 = ('date', 'fund', 'company', 'ticker', 'cusip', 'shares',\n",
    "        'market value ($)', 'weight (%)') # standard cols - labeled by the last verified file\n",
    "        extra_col = [i for i in input.columns if i not in col_20230110]\n",
    "        missing_col = [j for j in col_20230110 if j not in input.columns]\n",
    "\n",
    "        if len(extra_col) == 0:\n",
    "            print('Validated! The input data includes no non-standard cols!')\n",
    "        else:\n",
    "            print(('Warning:the input data includes non-standard col(s): {0}'.format(str(extra_col))))\n",
    "            print('Check the standard col list!')\n",
    "\n",
    "        if len(missing_col) == 0:\n",
    "            print('Validated! The input data includes all standard cols: {0}'.format(str(col_20230110)))\n",
    "        else:\n",
    "            print(('Warning:the input data miss: {0}'.format(str(missing_col))))\n",
    "            print('Check the standard col list!')\n",
    "        \n",
    "        return None\n",
    "\n",
    "    data_validation()\n",
    "\n",
    "    print('{0} data is checked! \\n'.format(fund_name))\n",
    "\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validated! The input data includes no non-standard cols!\n",
      "Validated! The input data includes all standard cols: ('date', 'fund', 'company', 'ticker', 'cusip', 'shares', 'market value ($)', 'weight (%)')\n",
      "ARKK data is checked! \n",
      "\n",
      "Validated! The input data includes no non-standard cols!\n",
      "Validated! The input data includes all standard cols: ('date', 'fund', 'company', 'ticker', 'cusip', 'shares', 'market value ($)', 'weight (%)')\n",
      "ARKW data is checked! \n",
      "\n",
      "Validated! The input data includes no non-standard cols!\n",
      "Validated! The input data includes all standard cols: ('date', 'fund', 'company', 'ticker', 'cusip', 'shares', 'market value ($)', 'weight (%)')\n",
      "ARKG data is checked! \n",
      "\n",
      "Validated! The input data includes no non-standard cols!\n",
      "Validated! The input data includes all standard cols: ('date', 'fund', 'company', 'ticker', 'cusip', 'shares', 'market value ($)', 'weight (%)')\n",
      "ARKQ data is checked! \n",
      "\n",
      "Validated! The input data includes no non-standard cols!\n",
      "Validated! The input data includes all standard cols: ('date', 'fund', 'company', 'ticker', 'cusip', 'shares', 'market value ($)', 'weight (%)')\n",
      "ARKF data is checked! \n",
      "\n",
      "Validated! The input data includes no non-standard cols!\n",
      "Validated! The input data includes all standard cols: ('date', 'fund', 'company', 'ticker', 'cusip', 'shares', 'market value ($)', 'weight (%)')\n",
      "ARKX data is checked! \n",
      "\n",
      "Validated! The input data includes no non-standard cols!\n",
      "Validated! The input data includes all standard cols: ('date', 'fund', 'company', 'ticker', 'cusip', 'shares', 'market value ($)', 'weight (%)')\n",
      "PRNT data is checked! \n",
      "\n",
      "Validated! The input data includes no non-standard cols!\n",
      "Validated! The input data includes all standard cols: ('date', 'fund', 'company', 'ticker', 'cusip', 'shares', 'market value ($)', 'weight (%)')\n",
      "IZRL data is checked! \n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i in np.arange(len(fund_name_tuple)):\n",
    "    data_validation_wrapper(input_dic=fund_raw_dic,\n",
    "                            fund_name=fund_name_tuple[i])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data lable is 05122023\n",
      "ARKK\n",
      "ARKW\n",
      "ARKG\n",
      "ARKQ\n",
      "ARKF\n",
      "ARKX\n",
      "PRNT\n",
      "IZRL\n"
     ]
    }
   ],
   "source": [
    "# Get the Date Label and Save as an Excel file\n",
    "date_label = fund_raw_dic['ARKF'].date[0].replace(\"/\",\"\")\n",
    "print('Data lable is {0}'.format(date_label))\n",
    "\n",
    "out_file_name = \"FundDs_\" + date_label + \".xlsx\"\n",
    "\n",
    "# Check if the data is already downloaded!\n",
    "import os\n",
    "\n",
    "if os.path.exists(os.path.join(input_dir, out_file_name)):\n",
    "    print('{0} data is already downloaded!'.format(date_label))\n",
    "else:\n",
    "    # Export dataframes to an .xlsx file\n",
    "    # Ref: https://pythonbasics.org/write-excel/#:~:text=You%20can%20write%20any%20data,use%20the%20to_excel()%20method.\n",
    "    with pd.ExcelWriter(os.path.join(input_dir, out_file_name)) as writer:\n",
    "        for tab_name, df in fund_raw_dic.items():\n",
    "            print(tab_name)\n",
    "            df.columns = ['date','fund', 'company', 'ticker', 'cusip', 'shares', 'MktVal_dollar', 'weight_pct'] # Rename the cols before saving\n",
    "            df.to_excel(writer, sheet_name = tab_name)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "0e60cb0986569fcb63371e2f12d0af5fa6011012376bb7868438abb93af89daa"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
