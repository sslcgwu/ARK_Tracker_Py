{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Notebook for Python ARK scraper development\n",
    "\n",
    "Some Technical Issues"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_dir = r'C:\\investment_ds\\ark_innovation\\input' # Save raw input here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'ARKK': 'https://ark-funds.com/wp-content/uploads/funds-etf-csv/ARK_INNOVATION_ETF_ARKK_HOLDINGS.csv', 'ARKW': 'https://ark-funds.com/wp-content/uploads/funds-etf-csv/ARK_NEXT_GENERATION_INTERNET_ETF_ARKW_HOLDINGS.csv', 'ARKG': 'https://ark-funds.com/wp-content/uploads/funds-etf-csv/ARK_GENOMIC_REVOLUTION_ETF_ARKG_HOLDINGS.csv', 'ARKQ': 'https://ark-funds.com/wp-content/uploads/funds-etf-csv/ARK_AUTONOMOUS_TECH._&_ROBOTICS_ETF_ARKQ_HOLDINGS.csv', 'ARKF': 'https://ark-funds.com/wp-content/uploads/funds-etf-csv/ARK_FINTECH_INNOVATION_ETF_ARKF_HOLDINGS.csv', 'ARKX': 'https://ark-funds.com/wp-content/uploads/funds-etf-csv/ARK_SPACE_EXPLORATION_&_INNOVATION_ETF_ARKX_HOLDINGS.csv', 'PRNT': 'https://ark-funds.com/wp-content/uploads/funds-etf-csv/THE_3D_PRINTING_ETF_PRNT_HOLDINGS.csv', 'IZRL': 'https://ark-funds.com/wp-content/uploads/funds-etf-csv/ARK_ISRAEL_INNOVATIVE_TECHNOLOGY_ETF_IZRL_HOLDINGS.csv'}\n"
     ]
    }
   ],
   "source": [
    "fund_name_tuple = ('ARKK', 'ARKW', 'ARKG', 'ARKQ', 'ARKF', 'ARKX','PRNT','IZRL')\n",
    "\n",
    "fund_data_source_tuple = ('https://ark-funds.com/wp-content/uploads/funds-etf-csv/ARK_INNOVATION_ETF_ARKK_HOLDINGS.csv',\n",
    "'https://ark-funds.com/wp-content/uploads/funds-etf-csv/ARK_NEXT_GENERATION_INTERNET_ETF_ARKW_HOLDINGS.csv',\n",
    "'https://ark-funds.com/wp-content/uploads/funds-etf-csv/ARK_GENOMIC_REVOLUTION_ETF_ARKG_HOLDINGS.csv',\n",
    "'https://ark-funds.com/wp-content/uploads/funds-etf-csv/ARK_AUTONOMOUS_TECH._&_ROBOTICS_ETF_ARKQ_HOLDINGS.csv',\n",
    "'https://ark-funds.com/wp-content/uploads/funds-etf-csv/ARK_FINTECH_INNOVATION_ETF_ARKF_HOLDINGS.csv',\n",
    "'https://ark-funds.com/wp-content/uploads/funds-etf-csv/ARK_SPACE_EXPLORATION_&_INNOVATION_ETF_ARKX_HOLDINGS.csv',\n",
    "'https://ark-funds.com/wp-content/uploads/funds-etf-csv/THE_3D_PRINTING_ETF_PRNT_HOLDINGS.csv',\n",
    "'https://ark-funds.com/wp-content/uploads/funds-etf-csv/ARK_ISRAEL_INNOVATIVE_TECHNOLOGY_ETF_IZRL_HOLDINGS.csv')\n",
    "\n",
    "input_dic = dict(zip(fund_name_tuple, fund_data_source_tuple))\n",
    "print(input_dic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ARKK data is loaded!\n",
      "ARKW data is loaded!\n",
      "ARKG data is loaded!\n",
      "ARKQ data is loaded!\n",
      "ARKF data is loaded!\n",
      "ARKX data is loaded!\n",
      "PRNT data is loaded!\n",
      "IZRL data is loaded!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "dict_keys(['ARKK', 'ARKW', 'ARKG', 'ARKQ', 'ARKF', 'ARKX', 'PRNT', 'IZRL'])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def read_web(select_fund, input_dict = input_dic, fund_name = fund_name_tuple):\n",
    "    if select_fund not in fund_name:\n",
    "        print(\"Please select fund from the tuple: {0:s}\".format(str(fund_name)))\n",
    "    else:\n",
    "        url = input_dict[select_fund]\n",
    "        storage_options = {'User-Agent': 'Chrome/108.0.5359.125'} # Need to specifify this line to read web file\n",
    "        fund_raw_ds = pd.read_csv(url, storage_options=storage_options) \n",
    "\n",
    "        print('{0} data is loaded!'.format(select_fund))\n",
    "\n",
    "        return fund_raw_ds\n",
    "\n",
    "fund_raw_dic = dict(zip(fund_name_tuple, (read_web(i) for i in fund_name_tuple)))\n",
    "\n",
    "fund_raw_dic.keys()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_validation_wrapper(input_dic, fund_name):\n",
    "    \n",
    "    input_ds = input_dic[fund_name]\n",
    "\n",
    "    def data_validation(input = input_ds):\n",
    "    # validate if col is modified\n",
    "    # input - the raw data frame\n",
    "        col_20230110 = ('date', 'fund', 'company', 'ticker', 'cusip', 'shares',\n",
    "        'market value ($)', 'weight (%)') # standard cols - labeled by the last verified file\n",
    "        extra_col = [i for i in input.columns if i not in col_20230110]\n",
    "        missing_col = [j for j in col_20230110 if j not in input.columns]\n",
    "\n",
    "        if len(extra_col) == 0:\n",
    "            print('Validated! The input data includes no non-standard cols!')\n",
    "        else:\n",
    "            print(('Warning:the input data includes non-standard col(s): {0}'.format(str(extra_col))))\n",
    "            print('Check the standard col list!')\n",
    "\n",
    "        if len(missing_col) == 0:\n",
    "            print('Validated! The input data includes all standard cols: {0}'.format(str(col_20230110)))\n",
    "        else:\n",
    "            print(('Warning:the input data miss: {0}'.format(str(missing_col))))\n",
    "            print('Check the standard col list!')\n",
    "        \n",
    "        return None\n",
    "\n",
    "    data_validation()\n",
    "\n",
    "    print('{0} data is checked! \\n'.format(fund_name))\n",
    "\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validated! The input data includes no non-standard cols!\n",
      "Validated! The input data includes all standard cols: ('date', 'fund', 'company', 'ticker', 'cusip', 'shares', 'market value ($)', 'weight (%)')\n",
      "ARKK data is checked! \n",
      "\n",
      "Validated! The input data includes no non-standard cols!\n",
      "Validated! The input data includes all standard cols: ('date', 'fund', 'company', 'ticker', 'cusip', 'shares', 'market value ($)', 'weight (%)')\n",
      "ARKW data is checked! \n",
      "\n",
      "Validated! The input data includes no non-standard cols!\n",
      "Validated! The input data includes all standard cols: ('date', 'fund', 'company', 'ticker', 'cusip', 'shares', 'market value ($)', 'weight (%)')\n",
      "ARKG data is checked! \n",
      "\n",
      "Validated! The input data includes no non-standard cols!\n",
      "Validated! The input data includes all standard cols: ('date', 'fund', 'company', 'ticker', 'cusip', 'shares', 'market value ($)', 'weight (%)')\n",
      "ARKQ data is checked! \n",
      "\n",
      "Validated! The input data includes no non-standard cols!\n",
      "Validated! The input data includes all standard cols: ('date', 'fund', 'company', 'ticker', 'cusip', 'shares', 'market value ($)', 'weight (%)')\n",
      "ARKF data is checked! \n",
      "\n",
      "Validated! The input data includes no non-standard cols!\n",
      "Validated! The input data includes all standard cols: ('date', 'fund', 'company', 'ticker', 'cusip', 'shares', 'market value ($)', 'weight (%)')\n",
      "ARKX data is checked! \n",
      "\n",
      "Validated! The input data includes no non-standard cols!\n",
      "Validated! The input data includes all standard cols: ('date', 'fund', 'company', 'ticker', 'cusip', 'shares', 'market value ($)', 'weight (%)')\n",
      "PRNT data is checked! \n",
      "\n",
      "Validated! The input data includes no non-standard cols!\n",
      "Validated! The input data includes all standard cols: ('date', 'fund', 'company', 'ticker', 'cusip', 'shares', 'market value ($)', 'weight (%)')\n",
      "IZRL data is checked! \n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i in np.arange(len(fund_name_tuple)):\n",
    "    data_validation_wrapper(input_dic=fund_raw_dic,\n",
    "                            fund_name=fund_name_tuple[i])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data lable is 12222023\n"
     ]
    },
    {
     "ename": "OSError",
     "evalue": "Cannot save file into a non-existent directory: 'C:\\investment_ds\\ark_innovation\\ark_tracker_py\\Input'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[14], line 15\u001b[0m\n\u001b[0;32m     11\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[38;5;124m data is already downloaded!\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mformat(date_label))\n\u001b[0;32m     12\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     13\u001b[0m     \u001b[38;5;66;03m# Export dataframes to an .xlsx file\u001b[39;00m\n\u001b[0;32m     14\u001b[0m     \u001b[38;5;66;03m# Ref: https://pythonbasics.org/write-excel/#:~:text=You%20can%20write%20any%20data,use%20the%20to_excel()%20method.\u001b[39;00m\n\u001b[1;32m---> 15\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mExcelWriter\u001b[49m\u001b[43m(\u001b[49m\u001b[43mos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpath\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mjoin\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_dir\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mout_file_name\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m writer:\n\u001b[0;32m     16\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m tab_name, df \u001b[38;5;129;01min\u001b[39;00m fund_raw_dic\u001b[38;5;241m.\u001b[39mitems():\n\u001b[0;32m     17\u001b[0m             \u001b[38;5;28mprint\u001b[39m(tab_name)\n",
      "File \u001b[1;32mc:\\conda\\anaconda3\\envs\\my_env\\lib\\site-packages\\pandas\\io\\excel\\_xlsxwriter.py:199\u001b[0m, in \u001b[0;36mXlsxWriter.__init__\u001b[1;34m(self, path, engine, date_format, datetime_format, mode, storage_options, if_sheet_exists, engine_kwargs, **kwargs)\u001b[0m\n\u001b[0;32m    196\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m mode \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124ma\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m    197\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAppend mode is not supported with xlsxwriter!\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m--> 199\u001b[0m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__init__\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[0;32m    200\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpath\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    201\u001b[0m \u001b[43m    \u001b[49m\u001b[43mengine\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mengine\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    202\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdate_format\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdate_format\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    203\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdatetime_format\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdatetime_format\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    204\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    205\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstorage_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    206\u001b[0m \u001b[43m    \u001b[49m\u001b[43mif_sheet_exists\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mif_sheet_exists\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    207\u001b[0m \u001b[43m    \u001b[49m\u001b[43mengine_kwargs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mengine_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    208\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    210\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_book \u001b[38;5;241m=\u001b[39m Workbook(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_handles\u001b[38;5;241m.\u001b[39mhandle, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mengine_kwargs)\n",
      "File \u001b[1;32mc:\\conda\\anaconda3\\envs\\my_env\\lib\\site-packages\\pandas\\io\\excel\\_base.py:1219\u001b[0m, in \u001b[0;36mExcelWriter.__init__\u001b[1;34m(self, path, engine, date_format, datetime_format, mode, storage_options, if_sheet_exists, engine_kwargs)\u001b[0m\n\u001b[0;32m   1215\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_handles \u001b[38;5;241m=\u001b[39m IOHandles(\n\u001b[0;32m   1216\u001b[0m     cast(IO[\u001b[38;5;28mbytes\u001b[39m], path), compression\u001b[38;5;241m=\u001b[39m{\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcompression\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28;01mNone\u001b[39;00m}\n\u001b[0;32m   1217\u001b[0m )\n\u001b[0;32m   1218\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(path, ExcelWriter):\n\u001b[1;32m-> 1219\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_handles \u001b[38;5;241m=\u001b[39m \u001b[43mget_handle\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1220\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpath\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstorage_options\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mis_text\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\n\u001b[0;32m   1221\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1222\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_cur_sheet \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1224\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m date_format \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\conda\\anaconda3\\envs\\my_env\\lib\\site-packages\\pandas\\io\\common.py:737\u001b[0m, in \u001b[0;36mget_handle\u001b[1;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[0;32m    735\u001b[0m \u001b[38;5;66;03m# Only for write methods\u001b[39;00m\n\u001b[0;32m    736\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m mode \u001b[38;5;129;01mand\u001b[39;00m is_path:\n\u001b[1;32m--> 737\u001b[0m     \u001b[43mcheck_parent_directory\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mhandle\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    739\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m compression:\n\u001b[0;32m    740\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m compression \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mzstd\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m    741\u001b[0m         \u001b[38;5;66;03m# compression libraries do not like an explicit text-mode\u001b[39;00m\n",
      "File \u001b[1;32mc:\\conda\\anaconda3\\envs\\my_env\\lib\\site-packages\\pandas\\io\\common.py:600\u001b[0m, in \u001b[0;36mcheck_parent_directory\u001b[1;34m(path)\u001b[0m\n\u001b[0;32m    598\u001b[0m parent \u001b[38;5;241m=\u001b[39m Path(path)\u001b[38;5;241m.\u001b[39mparent\n\u001b[0;32m    599\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m parent\u001b[38;5;241m.\u001b[39mis_dir():\n\u001b[1;32m--> 600\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mOSError\u001b[39;00m(\u001b[38;5;124mrf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCannot save file into a non-existent directory: \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mparent\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mOSError\u001b[0m: Cannot save file into a non-existent directory: 'C:\\investment_ds\\ark_innovation\\ark_tracker_py\\Input'"
     ]
    }
   ],
   "source": [
    "# Get the Date Label and Save as an Excel file\n",
    "date_label = fund_raw_dic['ARKF'].date[0].replace(\"/\",\"\")\n",
    "print('Data lable is {0}'.format(date_label))\n",
    "\n",
    "out_file_name = \"FundDs_\" + date_label + \".xlsx\"\n",
    "\n",
    "# Check if the data is already downloaded!\n",
    "import os\n",
    "\n",
    "if os.path.exists(os.path.join(input_dir, out_file_name)):\n",
    "    print('{0} data is already downloaded!'.format(date_label))\n",
    "else:\n",
    "    # Export dataframes to an .xlsx file\n",
    "    # Ref: https://pythonbasics.org/write-excel/#:~:text=You%20can%20write%20any%20data,use%20the%20to_excel()%20method.\n",
    "    with pd.ExcelWriter(os.path.join(input_dir, out_file_name)) as writer:\n",
    "        for tab_name, df in fund_raw_dic.items():\n",
    "            print(tab_name)\n",
    "            df.columns = ['date','fund', 'company', 'ticker', 'cusip', 'shares', 'MktVal_dollar', 'weight_pct'] # Rename the cols before saving\n",
    "            df.to_excel(writer, sheet_name = tab_name)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
